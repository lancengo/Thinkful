{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries into python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (0,19,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#load data set into python\n",
    "y2015 = pd.read_csv(\n",
    "    'https://www.dropbox.com/s/0so14yudedjmm5m/LoanStats3d.csv?dl=1',\n",
    "    skipinitialspace=True,\n",
    "    header=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ID and Interest Rate to numeric.\n",
    "y2015['id'] = pd.to_numeric(y2015['id'], errors='coerce')\n",
    "y2015['int_rate'] = pd.to_numeric(y2015['int_rate'].str.strip('%'), errors='coerce')\n",
    "\n",
    "# Drop other columns with many unique variables\n",
    "y2015.drop(['url', 'emp_title', 'zip_code', 'earliest_cr_line', 'revol_util',\n",
    "            'sub_grade', 'addr_state', 'desc','id','member_id'], 1, inplace=True)\n",
    "# Remove two summary rows at the end that don't actually contain data.\n",
    "y2015 = y2015[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the target variable and features\n",
    "x = y2015.drop('loan_status', 1)\n",
    "y = y2015['loan_status']\n",
    "x = pd.get_dummies(x, drop_first=True)\n",
    "x = x.dropna(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a train and test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9813937472541826"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize the random forest module and get the score\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "rfc.fit(x_train, y_train)\n",
    "rfc.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98081193, 0.98166684, 0.83730512, 0.76814021, 0.9808713 ])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the cross value score to check for overfitting\n",
    "cross_val_score(rfc, x, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create copy of the dataset\n",
    "df = y2015.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a copy of the target variable and features\n",
    "x2 = df.drop('loan_status', 1)\n",
    "y2 = df['loan_status']\n",
    "x2 = pd.get_dummies(x2, drop_first=True)\n",
    "x2 = x2.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a copy of the train/test splits\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/lib/python3.7/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/usr/local/lib/python3.7/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "#perform standard scaler on the numerical feature columns\n",
    "scaler = StandardScaler()\n",
    "categorical = df.select_dtypes(include=['object'])\n",
    "numerical = df.select_dtypes(include=['float'])\n",
    "numeric_col = numerical.columns\n",
    "x_train2[numeric_col] = scaler.fit_transform(x_train2[numeric_col])\n",
    "x_test2[numeric_col] = scaler.transform(x_test2[numeric_col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93752004, 0.95986654, 0.69296715, 0.74438072, 0.9605196 ])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize the random forest model and get the cross value score for the scaled features\n",
    "rfc2 = ensemble.RandomForestClassifier()\n",
    "rfc2.fit(x_train2, y_train2)\n",
    "cross_val_score(rfc2, x2, y2, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9625025231836046"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the accuracy of the model based on the test split\n",
    "rfc2.score(x_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform dimension reduction on the features via PCA\n",
    "pca = PCA(n_components = 10)\n",
    "pca.fit(x_train2)\n",
    "x_train_pca = pca.transform(x_train2)\n",
    "x_test_pca = pca.transform(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9259549507830774"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize the random forest model and scores for the PCA-scaled features\n",
    "rfc_pca = ensemble.RandomForestClassifier()\n",
    "rfc_pca.fit(x_train_pca, y_train2)\n",
    "rfc_pca.score(x_test_pca, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92446123, 0.9234852 , 0.92382716])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the cross value score for PCA-scaled data\n",
    "x_pca = np.concatenate([x_train_pca, x_test_pca], axis=0)\n",
    "y_pca = np.concatenate([y_train2, y_test2], axis=0)\n",
    "cross_val_score(rfc_pca, x_pca, y_pca, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9490613756990702"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize the neural network and get the accuracy\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,20))\n",
    "mlp.fit(x_train_pca, y_train2)\n",
    "mlp.score(x_test_pca, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94957432, 0.94956008, 0.94894739])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the cross value score to check for overfitting\n",
    "cross_val_score(mlp, x_pca, y_pca, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9491326185302604"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#intialize the neural network and get the accuracy\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,50))\n",
    "mlp.fit(x_train_pca, y_train2)\n",
    "mlp.score(x_test_pca, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94926086, 0.94978805, 0.94964557])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the cross value score and check for overfitting\n",
    "cross_val_score(mlp, x_pca, y_pca, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9489307638418885"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize the neural network and get the accuracy\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,50))\n",
    "mlp.fit(x_train_pca, y_train2)\n",
    "mlp.score(x_test_pca, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94931073, 0.94879778, 0.94904713])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the cross value score and check for overfitting\n",
    "cross_val_score(mlp, x_pca, y_pca, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9497975516213681"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize neural network and get accuracy\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,50), activation ='logistic')\n",
    "mlp.fit(x_train_pca, y_train2)\n",
    "mlp.score(x_test_pca, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94919674, 0.94962419, 0.94914687])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get cross value score\n",
    "cross_val_score(mlp, x_pca, y_pca, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9496075707381945"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize neural network and get accuracy\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,50), activation ='logistic')\n",
    "mlp.fit(x_train_pca, y_train2)\n",
    "mlp.score(x_test_pca, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94968831, 0.94955295, 0.95001603])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get cross value score\n",
    "cross_val_score(mlp, x_pca, y_pca, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using this data set with a random forest model and a 2 layer neural network, the neural network gave better results. After varying the hyperparameter of the neural network, the averages were around 94.8 - 95% compared to the 92.3% of the random forest. While the accuracy of the neural network was better, the tradeoff was the complexity and time-consumption. The random forest was considerably faster to train and fit while also would have some explainability in the feature importance. This would at least tell us what features are influencing the model the most."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
